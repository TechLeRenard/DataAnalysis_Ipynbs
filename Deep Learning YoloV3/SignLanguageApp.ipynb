{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements for this program to run.\n",
    "* Install the following via Anaconda Prompt\n",
    "    - pyqt5 (pip install pyqt5)\n",
    "    - pyqt5-tools (pip install pyqt5-tools)\n",
    "    - tensorflow\n",
    "    - imageai\n",
    "* Trianed Model and .json file (Both must be located as the same path of this file)\n",
    "* Qt Designer\n",
    "* Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App System Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jimmuel\\anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MyWindow' object has no attribute 'popupImage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d12db5b230d3>\u001b[0m in \u001b[0;36mgetImage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mglobal\u001b[0m \u001b[0mimagePath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mimagePath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDetectImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;31m#Code For Single Image Detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-d12db5b230d3>\u001b[0m in \u001b[0;36mDetectImage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0meachObject\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdetections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meachObject\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meachObject\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"percentage_probability\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopupImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;31m#Show popup Window after Finishing the Image Detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MyWindow' object has no attribute 'popupImage'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Frame :  1\n",
      "Processing Frame :  2\n",
      "Processing Frame :  3\n",
      "Processing Frame :  4\n",
      "Processing Frame :  5\n",
      "Processing Frame :  6\n",
      "Processing Frame :  7\n",
      "Processing Frame :  8\n",
      "Processing Frame :  9\n",
      "Processing Frame :  10\n",
      "Processing Frame :  11\n",
      "Processing Frame :  12\n",
      "Processing Frame :  13\n",
      "Processing Frame :  14\n",
      "Processing Frame :  15\n",
      "Processing Frame :  16\n",
      "Processing Frame :  17\n",
      "Processing Frame :  18\n",
      "Processing Frame :  19\n",
      "Processing Frame :  20\n",
      "Processing Frame :  21\n",
      "Processing Frame :  22\n",
      "Processing Frame :  23\n",
      "Processing Frame :  24\n",
      "Processing Frame :  25\n",
      "Processing Frame :  26\n",
      "Processing Frame :  27\n",
      "Processing Frame :  28\n",
      "Processing Frame :  29\n",
      "Processing Frame :  30\n",
      "Processing Frame :  31\n",
      "Processing Frame :  32\n",
      "Processing Frame :  33\n",
      "Processing Frame :  34\n",
      "Processing Frame :  35\n",
      "Processing Frame :  36\n",
      "Processing Frame :  37\n",
      "Processing Frame :  38\n",
      "Processing Frame :  39\n",
      "Processing Frame :  40\n",
      "Processing Frame :  41\n",
      "Processing Frame :  42\n",
      "Processing Frame :  43\n",
      "Processing Frame :  44\n",
      "Processing Frame :  45\n",
      "Processing Frame :  46\n",
      "Processing Frame :  47\n",
      "Processing Frame :  48\n",
      "Processing Frame :  49\n",
      "Processing Frame :  50\n",
      "Processing Frame :  51\n",
      "Processing Frame :  52\n",
      "Processing Frame :  53\n",
      "Processing Frame :  54\n",
      "Processing Frame :  55\n",
      "Processing Frame :  56\n",
      "Processing Frame :  57\n",
      "Processing Frame :  58\n",
      "Processing Frame :  59\n",
      "Processing Frame :  60\n",
      "Processing Frame :  61\n",
      "Processing Frame :  62\n",
      "Processing Frame :  63\n",
      "Processing Frame :  64\n",
      "Processing Frame :  65\n",
      "Processing Frame :  66\n",
      "Processing Frame :  67\n",
      "Processing Frame :  68\n",
      "Processing Frame :  69\n",
      "Processing Frame :  70\n",
      "Processing Frame :  71\n",
      "Processing Frame :  72\n",
      "Processing Frame :  73\n",
      "Processing Frame :  74\n",
      "Processing Frame :  75\n",
      "Processing Frame :  76\n",
      "Processing Frame :  77\n",
      "Processing Frame :  78\n",
      "Processing Frame :  79\n",
      "Processing Frame :  80\n",
      "Processing Frame :  81\n",
      "Processing Frame :  82\n",
      "Processing Frame :  83\n",
      "Processing Frame :  84\n",
      "Processing Frame :  85\n",
      "Processing Frame :  86\n",
      "Processing Frame :  87\n",
      "Processing Frame :  88\n",
      "Processing Frame :  89\n",
      "Processing Frame :  90\n",
      "Processing Frame :  91\n",
      "Processing Frame :  92\n",
      "Processing Frame :  93\n",
      "Processing Frame :  94\n",
      "Processing Frame :  95\n",
      "Processing Frame :  96\n",
      "Processing Frame :  97\n",
      "Processing Frame :  98\n",
      "Processing Frame :  99\n",
      "Processing Frame :  100\n",
      "Processing Frame :  101\n",
      "Processing Frame :  102\n",
      "Processing Frame :  103\n",
      "Processing Frame :  104\n",
      "Processing Frame :  105\n",
      "Processing Frame :  106\n",
      "Processing Frame :  107\n",
      "Processing Frame :  108\n",
      "Processing Frame :  109\n",
      "Processing Frame :  110\n",
      "Processing Frame :  111\n",
      "Processing Frame :  112\n",
      "Processing Frame :  113\n",
      "Processing Frame :  114\n",
      "Processing Frame :  115\n",
      "Processing Frame :  116\n",
      "Processing Frame :  117\n",
      "Processing Frame :  118\n",
      "Processing Frame :  119\n",
      "Processing Frame :  120\n",
      "Processing Frame :  121\n",
      "Processing Frame :  122\n",
      "Processing Frame :  123\n",
      "Processing Frame :  124\n",
      "Processing Frame :  125\n",
      "Processing Frame :  126\n",
      "Processing Frame :  127\n",
      "Processing Frame :  128\n",
      "Processing Frame :  129\n",
      "Processing Frame :  130\n",
      "Processing Frame :  131\n",
      "Processing Frame :  132\n",
      "Processing Frame :  133\n",
      "Processing Frame :  134\n",
      "Processing Frame :  135\n",
      "Processing Frame :  136\n",
      "Processing Frame :  137\n",
      "Processing Frame :  138\n",
      "Processing Frame :  139\n",
      "Processing Frame :  140\n",
      "Processing Frame :  141\n",
      "Processing Frame :  142\n",
      "Processing Frame :  143\n",
      "Processing Frame :  144\n",
      "Processing Frame :  145\n",
      "Processing Frame :  146\n",
      "Processing Frame :  147\n",
      "Processing Frame :  148\n",
      "Processing Frame :  149\n",
      "Processing Frame :  150\n",
      "Processing Frame :  151\n",
      "Processing Frame :  152\n",
      "Processing Frame :  153\n",
      "Processing Frame :  154\n",
      "Processing Frame :  155\n",
      "Processing Frame :  156\n",
      "Processing Frame :  157\n",
      "Processing Frame :  158\n",
      "Processing Frame :  159\n",
      "Processing Frame :  160\n",
      "Processing Frame :  161\n",
      "Processing Frame :  162\n",
      "Processing Frame :  163\n",
      "Processing Frame :  164\n",
      "Processing Frame :  165\n",
      "Processing Frame :  166\n",
      "Processing Frame :  167\n",
      "Processing Frame :  168\n",
      "Processing Frame :  169\n",
      "Processing Frame :  170\n",
      "Processing Frame :  171\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "#-------------------------------------------------\n",
    "from PyQt5 import QtWidgets, QtGui, QtCore\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QDesktopWidget, QFileDialog, QMessageBox\n",
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import csv \n",
    "import time\n",
    "import csv\n",
    "import argparse \n",
    "import datetime \n",
    "import pandas as pd\n",
    "#-------------------------------------------------\n",
    "\n",
    "#Application's Details\n",
    "#-------------------------------------------------\n",
    "class MyWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super(MyWindow, self).__init__()\n",
    "        #Set Fixed Resolution Size to 600\n",
    "        self.setFixedSize(800, 370)\n",
    "        self.setWindowTitle(\"Hololens Detection System Using Deep Learning\")\n",
    "        #Background Color\n",
    "        self.setStyleSheet(\"background:rgb(199,211,239)\")\n",
    "        self.initUI()\n",
    "        self.center()\n",
    "#-------------------------------------------------\n",
    "        \n",
    "#Set Form to Center Screen\n",
    "#-------------------------------------------------\n",
    "    def center(self):\n",
    "        qr = self.frameGeometry()\n",
    "        cp = QDesktopWidget().availableGeometry().center()\n",
    "        qr.moveCenter(cp)\n",
    "        self.move(qr.topLeft())\n",
    "#-------------------------------------------------\n",
    "    \n",
    "#Code for widgets (Labels and Buttons)\n",
    "#-------------------------------------------------\n",
    "    def initUI(self):\n",
    "            \n",
    "            #Title Label\n",
    "            self.title = QtWidgets.QLabel(self)\n",
    "            self.title.setText(\"SIGN LANGUAGE RECOGNITION THROUGH DEEP LEARNING\")    \n",
    "            self.title.setFont(QtGui.QFont('Arial', 16))\n",
    "            self.title.setStyleSheet(\"font-weight: bold\");\n",
    "            self.title.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.title.setGeometry(QtCore.QRect(0, 20, 801, 61))\n",
    "            \n",
    "            #Label 1\n",
    "            self.label = QtWidgets.QLabel(self)\n",
    "            self.label.setText(\"TRAINED USING YOLO V3 ALGORITHM\")    \n",
    "            self.label.setFont(QtGui.QFont('Arial', 9))\n",
    "            self.label.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.label.setGeometry(QtCore.QRect(0, 10, 801, 31))\n",
    "            \n",
    "            #Label 2\n",
    "            self.label2 = QtWidgets.QLabel(self)\n",
    "            self.label2.setText(\"WITH SECURITY APPLICATION\")    \n",
    "            self.label2.setFont(QtGui.QFont('Arial', 9))\n",
    "            self.label2.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.label2.setGeometry(QtCore.QRect(0, 60, 791, 31))\n",
    "                        \n",
    "            #Image Label\n",
    "            self.Imglabel = QtWidgets.QLabel(self)\n",
    "            self.Imglabel.setText(\"IMAGE\")    \n",
    "            self.Imglabel.setFont(QtGui.QFont('Arial', 16))\n",
    "            self.Imglabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.Imglabel.setGeometry(QtCore.QRect(90, 120, 111, 41))\n",
    "            \n",
    "            #Image Button\n",
    "            self.ImgBtn = QtWidgets.QPushButton(self)\n",
    "            self.ImgBtn.setGeometry(QtCore.QRect(60, 160, 165, 165))\n",
    "            self.ImgBtn.setText(\"\")\n",
    "            \n",
    "            \n",
    "            #Image Icon\n",
    "            imgbtnicon = QtGui.QIcon()\n",
    "            imgbtnicon.addPixmap(QtGui.QPixmap(\"art/image1.png\"), QtGui.QIcon.Normal, QtGui.QIcon.Off)\n",
    "            self.ImgBtn.setIcon(imgbtnicon)\n",
    "            self.ImgBtn.setIconSize(QtCore.QSize(160, 160))\n",
    "            self.ImgBtn.setFlat(True)\n",
    "            \n",
    "            #Image Button Click Event\n",
    "            self.ImgBtn.clicked.connect(self.getImage)\n",
    "            \n",
    "            #Import Image Label\n",
    "            self.impimglabel = QtWidgets.QLabel(self)\n",
    "            self.impimglabel.setText(\"GET IMAGE\")\n",
    "            self.impimglabel.setFont(QtGui.QFont('Arial', 9))\n",
    "            self.impimglabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.impimglabel.setGeometry(QtCore.QRect(65, 330, 161, 31))\n",
    "            \n",
    "            #Video Label\n",
    "            self.Vidlabel = QtWidgets.QLabel(self)\n",
    "            self.Vidlabel.setText(\"VIDEO\")\n",
    "            self.Vidlabel.setFont(QtGui.QFont('Arial', 16))\n",
    "            self.Vidlabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.Vidlabel.setGeometry(QtCore.QRect(590, 110, 101, 51))\n",
    "            \n",
    "            #Video Button\n",
    "            self.VidBtn = QtWidgets.QPushButton(self)\n",
    "            self.VidBtn.setGeometry(QtCore.QRect(560, 160, 165, 165))\n",
    "            self.VidBtn.setText(\"\")\n",
    "            \n",
    "            #Video Icon\n",
    "            vidbtnicon = QtGui.QIcon()\n",
    "            vidbtnicon.addPixmap(QtGui.QPixmap(\"art/video.png\"), QtGui.QIcon.Normal, QtGui.QIcon.Off)\n",
    "            self.VidBtn.setIcon(vidbtnicon)\n",
    "            self.VidBtn.setIconSize(QtCore.QSize(160, 160))\n",
    "            self.VidBtn.setFlat(True)                        \n",
    "            \n",
    "            #Button Click Event\n",
    "            self.VidBtn.clicked.connect(self.getVideo)\n",
    "            \n",
    "            #Import Video Label\n",
    "            self.impvidlabel = QtWidgets.QLabel(self)\n",
    "            self.impvidlabel.setText(\"GET VIDEO\")\n",
    "            self.impvidlabel.setFont(QtGui.QFont('Arial', 9))\n",
    "            self.impvidlabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.impvidlabel.setGeometry(QtCore.QRect(565, 330, 161, 31))\n",
    "            \n",
    "            #Live Label\n",
    "            self.livelabel = QtWidgets.QLabel(self)\n",
    "            self.livelabel.setText(\"WEBCAM\")\n",
    "            self.livelabel.setFont(QtGui.QFont('Arial', 16))\n",
    "            self.livelabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.livelabel.setGeometry(QtCore.QRect(315, 110, 171, 51))\n",
    "            \n",
    "            #Live Button\n",
    "            self.livebtn = QtWidgets.QPushButton(self)\n",
    "            self.livebtn.setGeometry(QtCore.QRect(320, 160, 165, 165))\n",
    "            self.livebtn.setText(\"\")\n",
    "            \n",
    "            #Live Icon\n",
    "            livebtnicon = QtGui.QIcon()\n",
    "            livebtnicon.addPixmap(QtGui.QPixmap(\"art/webcam.png\"), QtGui.QIcon.Normal, QtGui.QIcon.Off)\n",
    "            self.livebtn.setIcon(livebtnicon)\n",
    "            self.livebtn.setIconSize(QtCore.QSize(160, 160))\n",
    "            self.livebtn.setFlat(True) \n",
    "            \n",
    "            #Button Click Event\n",
    "            self.livebtn.clicked.connect(self.Livestream)\n",
    "            \n",
    "            #Import Live Label\n",
    "            self.implivelabel = QtWidgets.QLabel(self)\n",
    "            self.implivelabel.setText(\"LIVE FEED\")\n",
    "            self.implivelabel.setFont(QtGui.QFont('Arial', 9))\n",
    "            self.implivelabel.setAlignment(QtCore.Qt.AlignCenter)\n",
    "            self.implivelabel.setGeometry(QtCore.QRect(340, 330, 131, 31))\n",
    "#-------------------------------------------------\n",
    "\n",
    "#Select Image from your Computer to Detect\n",
    "#-------------------------------------------------\n",
    "    def getImage(self):\n",
    "        fname = QFileDialog.getOpenFileName(self, 'Open file', 'c:/',\"Image files (*.jpg *.png)\")\n",
    "        #Setting Variable name \"imagePath\" to global so it can be called at def DetectImage()\n",
    "        global imagePath\n",
    "        imagePath = fname[0]\n",
    "        self.DetectImage()\n",
    "        \n",
    "#Code For Single Image Detection\n",
    "#-------------------------------------------------\n",
    "    def DetectImage(self):\n",
    "        from datetime import datetime\n",
    "        today = datetime.now()\n",
    "        #Main Code for Hololens\n",
    "        detector = CustomObjectDetection()\n",
    "        detector.setModelTypeAsYOLOv3()\n",
    "        #Model Used\n",
    "        detector.setModelPath(\"model.h5\")\n",
    "        detector.setJsonPath(\"json.json\")\n",
    "        detector.loadModel()\n",
    "        detections = detector.detectObjectsFromImage(input_image=imagePath, output_image_path= imagePath + \"hand.jpg\", minimum_percentage_probability=30)\n",
    "        \n",
    "    \n",
    "        #Create CSV File from the image\n",
    "        with open('single-image.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            #columns name\n",
    "            writer.writerow(['CLASS', 'PERCENTAGE'])\n",
    "            for (eachObject) in detections:\n",
    "                writer.writerow([eachObject[\"name\"], eachObject[\"percentage_probability\"]])\n",
    "        self.popupImage()\n",
    "\n",
    "#Show popup Window after Finishing the Image Detection\n",
    "#-------------------------------------------------\n",
    "    def popupVid(self):\n",
    "        msg = QMessageBox()\n",
    "        msg.setWindowTitle(\"Single-Image Detection\")\n",
    "        msg.setText(\"Single Detection Finish\")\n",
    "        msg.setIcon(QMessageBox.Information)\n",
    "        x = msg2.exec_()\n",
    "\n",
    "\n",
    "#Select Video from your Computer to Detect\n",
    "#-------------------------------------------------\n",
    "    def getVideo(self):\n",
    "        vidname = QFileDialog.getOpenFileName(self, 'Open file', 'c:/',\"Video files (*.avi *.mp4)\")\n",
    "        #Setting Variable name \"aviPath\" to global so it can be called at def DetectImage()\n",
    "        global aviPath\n",
    "        aviPath = vidname[0]\n",
    "        #call def DectectVideo\n",
    "        self.DetectVideo()\n",
    "        \n",
    "#Code for Video Detection\n",
    "#-------------------------------------------------\n",
    "    def DetectVideo(self):\n",
    "        from datetime import datetime\n",
    "        classid = []\n",
    "        percentage =[]\n",
    "        execution_path = os.getcwd()\n",
    "\n",
    "    # FOR HOLOLENS DETECTION\n",
    "        def forFrame(frame_number, output_array, output_count):\n",
    "            for eachObject in output_array:\n",
    "                classid.append(eachObject[\"name\"])\n",
    "                percentage.append(eachObject[\"percentage_probability\"])\n",
    "                \n",
    "        rec_detector = CustomVideoObjectDetection()\n",
    "        rec_detector.setModelTypeAsYOLOv3()\n",
    "        rec_detector.setModelPath(\"model.h5\")\n",
    "        rec_detector.setJsonPath(\"json.json\")\n",
    "        rec_detector.loadModel()\n",
    "        rec_detector.detectObjectsFromVideo(input_file_path=aviPath,\n",
    "                                                  output_file_path=os.path.join(execution_path, aviPath + \"detected_hololens\"),\n",
    "                                                  per_frame_function=forFrame,\n",
    "                                                  minimum_percentage_probability=30,\n",
    "                                                  log_progress=True)\n",
    "        \n",
    "        \n",
    "        #Create CSV File from the image\n",
    "        with open('video-image.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            #columns name\n",
    "            writer.writerow(['CLASS', 'PERCENTAGE'])\n",
    "            for (classid_x, percentage_x) in zip (classid, percentage):\n",
    "                writer.writerow([classid_x, percentage_x])\n",
    "        self.popupVid()\n",
    "        \n",
    "        \n",
    "#Show popup Window after Finishing the Video Detection\n",
    "#-------------------------------------------------\n",
    "    def popupVid(self):\n",
    "        msg2 = QMessageBox()\n",
    "        msg2.setWindowTitle(\"Video Detection\")\n",
    "        msg2.setText(\"Video Dectection Finish\")\n",
    "        msg2.setIcon(QMessageBox.Information)\n",
    "        y = msg2.exec_()\n",
    "        \n",
    "#Code for Live Detection\n",
    "#-------------------------------------------------\n",
    "    def Livestream(self):\n",
    "        from datetime import datetime\n",
    "        classid = []\n",
    "        percentage =[]\n",
    "\n",
    "        execution_path = os.getcwd()\n",
    "        \n",
    "        camera = cv2.VideoCapture(0)\n",
    "        \n",
    "    # FOR HOLOLENS DETECTION\n",
    "        #Get Values\n",
    "        def forFrame(frame_number, output_array, output_count):\n",
    "            for eachObject in output_array:\n",
    "                classid.append(eachObject[\"name\"])\n",
    "                percentage.append(eachObject[\"percentage_probability\"])\n",
    "                \n",
    "        video_detector = CustomVideoObjectDetection()\n",
    "        video_detector.setModelTypeAsYOLOv3()\n",
    "        #Model Used\n",
    "        video_detector.setModelPath(\"model.h5\")\n",
    "        video_detector.setJsonPath(\"json.json\")\n",
    "        video_detector.loadModel()\n",
    "        #Timer is Set to 3 Seconds, to change, change dection_timeout value to desired seconds.\n",
    "        video_detector.detectObjectsFromVideo(camera_input=camera, \n",
    "                                                            output_file_path=os.path.join(execution_path, \"LiveFeedOutput\"),\n",
    "                                                            per_frame_function=forFrame,  minimum_percentage_probability=50,\n",
    "                                                            detection_timeout=3)\n",
    "\n",
    "        \n",
    "        #Create CSV File from the image\n",
    "        with open('live_data.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            #columns name\n",
    "            writer.writerow(['CLASS', 'PERCENTAGE'])\n",
    "            for (classid_x, percentage_x) in zip (classid, percentage):\n",
    "                writer.writerow([classid_x, percentage_x])\n",
    "        self.popupLive()\n",
    "        \n",
    "        \n",
    "#Show popup Window after Finishing the Live Detection\n",
    "#-------------------------------------------------\n",
    "    def popupLive(self):\n",
    "        msg3 = QMessageBox()\n",
    "        msg3.setWindowTitle(\"Live Detection\")\n",
    "        msg3.setText(\"Live Dectection Finish\")\n",
    "        msg3.setIcon(QMessageBox.Information)\n",
    "        z = msg3.exec_()\n",
    "        \n",
    "#Open Form\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    win = MyWindow()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
